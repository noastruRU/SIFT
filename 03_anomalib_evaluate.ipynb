{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8842026",
   "metadata": {},
   "source": [
    "## 1. Setup & Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb07139c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, confusion_matrix\n",
    "from anomalib.models import Patchcore\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Device\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {DEVICE}\")\n",
    "\n",
    "# Paths\n",
    "CHECKPOINT_DIR = Path(\"checkpoints\")\n",
    "TEST_GOOD = Path(\"dataset\") / \"test\" / \"good\"\n",
    "TEST_DEFECT = Path(\"dataset\") / \"test\" / \"defect\"\n",
    "RESULTS_DIR = Path(\"evaluation_results\")\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Load model\n",
    "model = Patchcore.load_from_checkpoint(CHECKPOINT_DIR / \"patchcore_trained.ckpt\")\n",
    "model = model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "print(\"‚úì Model loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f8cc6b",
   "metadata": {},
   "source": [
    "## 2. Prepare Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758d8a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Prepare transform (same as training)\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def load_test_images(folder_path):\n",
    "    \"\"\"\n",
    "    Load all images from a folder.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    paths = []\n",
    "    \n",
    "    for ext in ['*.png', '*.jpg', '*.jpeg']:\n",
    "        for img_path in Path(folder_path).glob(ext):\n",
    "            try:\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                img_tensor = test_transform(img)\n",
    "                images.append(img_tensor)\n",
    "                paths.append(img_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {img_path}: {e}\")\n",
    "    \n",
    "    return images, paths\n",
    "\n",
    "# Load test images\n",
    "print(\"Loading test images...\")\n",
    "good_images, good_paths = load_test_images(TEST_GOOD)\n",
    "defect_images, defect_paths = load_test_images(TEST_DEFECT)\n",
    "\n",
    "print(f\"‚úì Good images: {len(good_images)}\")\n",
    "print(f\"‚úì Defect images: {len(defect_images)}\")\n",
    "print(f\"‚úì Total test images: {len(good_images) + len(defect_images)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72b7923",
   "metadata": {},
   "source": [
    "## 3. Generate Anomaly Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8131c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_anomaly_score(model, images, device):\n",
    "    \"\"\"\n",
    "    Generate anomaly scores for a batch of images.\n",
    "    Returns: anomaly scores (higher = more anomalous)\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for img in images:\n",
    "            img_batch = img.unsqueeze(0).to(device)\n",
    "            output = model.predict(img_batch)\n",
    "            \n",
    "            # Extract anomaly score\n",
    "            if isinstance(output, dict):\n",
    "                score = output.get('anomaly_score', output.get('score', 0.0))\n",
    "            else:\n",
    "                score = output.item() if isinstance(output, torch.Tensor) else float(output)\n",
    "            \n",
    "            scores.append(score)\n",
    "    \n",
    "    return np.array(scores)\n",
    "\n",
    "# Generate scores\n",
    "print(\"Generating anomaly scores...\")\n",
    "good_scores = predict_anomaly_score(model, good_images, DEVICE)\n",
    "defect_scores = predict_anomaly_score(model, defect_images, DEVICE)\n",
    "\n",
    "print(f\"‚úì Good images anomaly scores generated\")\n",
    "print(f\"  Mean: {good_scores.mean():.4f}, Std: {good_scores.std():.4f}\")\n",
    "print(f\"  Min: {good_scores.min():.4f}, Max: {good_scores.max():.4f}\")\n",
    "\n",
    "print(f\"‚úì Defect images anomaly scores generated\")\n",
    "print(f\"  Mean: {defect_scores.mean():.4f}, Std: {defect_scores.std():.4f}\")\n",
    "print(f\"  Min: {defect_scores.min():.4f}, Max: {defect_scores.max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745cdd8b",
   "metadata": {},
   "source": [
    "## 4. ROC Curve & Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfaecd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine labels: 0 = good, 1 = defect\n",
    "y_true = np.concatenate([np.zeros(len(good_scores)), np.ones(len(defect_scores))])\n",
    "y_scores = np.concatenate([good_scores, defect_scores])\n",
    "\n",
    "# Calculate ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Find optimal threshold (Youden's index)\n",
    "youden_index = tpr - fpr\n",
    "optimal_idx = np.argmax(youden_index)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"EVALUATION METRICS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nROC-AUC Score: {roc_auc:.4f}\")\n",
    "print(f\"Optimal Threshold: {optimal_threshold:.4f}\")\n",
    "print(f\"Youden Index: {youden_index[optimal_idx]:.4f}\")\n",
    "print(f\"\\nAt optimal threshold:\")\n",
    "print(f\"  True Positive Rate: {tpr[optimal_idx]:.4f}\")\n",
    "print(f\"  False Positive Rate: {fpr[optimal_idx]:.4f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "y_pred = (y_scores >= optimal_threshold).astype(int)\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(f\"  True Negatives (Good detected as good): {tn}\")\n",
    "print(f\"  False Positives (Good detected as defect): {fp}\")\n",
    "print(f\"  False Negatives (Defect detected as good): {fn}\")\n",
    "print(f\"  True Positives (Defect detected as defect): {tp}\")\n",
    "\n",
    "sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "print(f\"\\nSensitivity (Recall): {sensitivity:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c677e47c",
   "metadata": {},
   "source": [
    "## 5. ROC Curve Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1f1fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curve\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
    "plt.scatter(fpr[optimal_idx], tpr[optimal_idx], color='red', s=100, marker='o', label=f'Optimal Threshold = {optimal_threshold:.4f}')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - Patchcore Anomaly Detection')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save\n",
    "roc_path = RESULTS_DIR / \"roc_curve.png\"\n",
    "plt.savefig(roc_path, dpi=150)\n",
    "print(f\"‚úì ROC curve saved to: {roc_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01639a9",
   "metadata": {},
   "source": [
    "## 6. Score Distribution Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dc7a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot score distributions\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(good_scores, bins=20, alpha=0.7, label='Good', color='green', edgecolor='black')\n",
    "plt.hist(defect_scores, bins=20, alpha=0.7, label='Defect', color='red', edgecolor='black')\n",
    "plt.axvline(optimal_threshold, color='blue', linestyle='--', linewidth=2, label=f'Threshold = {optimal_threshold:.4f}')\n",
    "plt.xlabel('Anomaly Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Anomaly Score Distribution')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot([good_scores, defect_scores], labels=['Good', 'Defect'])\n",
    "plt.axhline(optimal_threshold, color='blue', linestyle='--', linewidth=2)\n",
    "plt.ylabel('Anomaly Score')\n",
    "plt.title('Score Distribution (Boxplot)')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save\n",
    "dist_path = RESULTS_DIR / \"score_distribution.png\"\n",
    "plt.savefig(dist_path, dpi=150)\n",
    "print(f\"‚úì Distribution plot saved to: {dist_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca3f340",
   "metadata": {},
   "source": [
    "## 7. Sample Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656c7831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some examples with their scores\n",
    "fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "fig.suptitle('Patchcore Anomaly Detection Examples', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Good images\n",
    "for i in range(3):\n",
    "    idx = i * 2 % len(good_paths)\n",
    "    img = Image.open(good_paths[idx]).convert('RGB')\n",
    "    score = good_scores[idx]\n",
    "    \n",
    "    axes[0, i].imshow(img)\n",
    "    axes[0, i].set_title(f'Good (Score: {score:.3f})', color='green', fontweight='bold')\n",
    "    axes[0, i].axis('off')\n",
    "\n",
    "# Defect images\n",
    "for i in range(3):\n",
    "    idx = i * 2 % len(defect_paths)\n",
    "    img = Image.open(defect_paths[idx]).convert('RGB')\n",
    "    score = defect_scores[idx]\n",
    "    \n",
    "    axes[1, i].imshow(img)\n",
    "    axes[1, i].set_title(f'Defect (Score: {score:.3f})', color='red', fontweight='bold')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "# Hide unused subplots\n",
    "for i in range(3, 4):\n",
    "    for j in range(4):\n",
    "        axes[i, j].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save\n",
    "samples_path = RESULTS_DIR / \"sample_detections.png\"\n",
    "plt.savefig(samples_path, dpi=150)\n",
    "print(f\"‚úì Samples saved to: {samples_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d57b22",
   "metadata": {},
   "source": [
    "## 8. Save Evaluation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40c9a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Save results summary\n",
    "results = {\n",
    "    \"model\": \"Patchcore (wide_resnet50_2)\",\n",
    "    \"metrics\": {\n",
    "        \"roc_auc\": float(roc_auc),\n",
    "        \"optimal_threshold\": float(optimal_threshold),\n",
    "        \"sensitivity\": float(sensitivity),\n",
    "        \"specificity\": float(specificity),\n",
    "        \"true_positives\": int(tp),\n",
    "        \"true_negatives\": int(tn),\n",
    "        \"false_positives\": int(fp),\n",
    "        \"false_negatives\": int(fn)\n",
    "    },\n",
    "    \"score_statistics\": {\n",
    "        \"good_mean\": float(good_scores.mean()),\n",
    "        \"good_std\": float(good_scores.std()),\n",
    "        \"defect_mean\": float(defect_scores.mean()),\n",
    "        \"defect_std\": float(defect_scores.std())\n",
    "    },\n",
    "    \"test_set_sizes\": {\n",
    "        \"good_images\": len(good_scores),\n",
    "        \"defect_images\": len(defect_scores)\n",
    "    }\n",
    "}\n",
    "\n",
    "results_path = RESULTS_DIR / \"evaluation_results.json\"\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"‚úì Results saved to: {results_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477c955c",
   "metadata": {},
   "source": [
    "## 9. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e46e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EVALUATION COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüìä Results:\")\n",
    "print(f\"  ROC-AUC: {roc_auc:.4f}\")\n",
    "print(f\"  Optimal Threshold: {optimal_threshold:.4f}\")\n",
    "print(f\"  Sensitivity: {sensitivity:.4f}\")\n",
    "print(f\"  Specificity: {specificity:.4f}\")\n",
    "print(f\"\\nüìÅ Saved outputs:\")\n",
    "print(f\"  - ROC curve: {roc_path}\")\n",
    "print(f\"  - Score distribution: {dist_path}\")\n",
    "print(f\"  - Sample detections: {samples_path}\")\n",
    "print(f\"  - Metrics JSON: {results_path}\")\n",
    "print(f\"\\nüöÄ Next: Run 04_anomalib_inference.ipynb for inference on new images\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
