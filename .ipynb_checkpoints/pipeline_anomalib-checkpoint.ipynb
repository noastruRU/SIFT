{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d2b20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment to run)\n",
    "# !pip install -r requirements.txt\n",
    "# !pip install anomalib pytorch-lightning\n",
    "# Optional: pillow-heif if you have HEIC images\n",
    "# !pip install pillow-heif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b5811c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - set paths here\n",
    "from pathlib import Path\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env if present\n",
    "load_dotenv()\n",
    "\n",
    "# Folder containing your already-segmented/cropped nut images (change as needed)\n",
    "SEGMENTED_DIR = Path(os.getenv('SEGMENTED_DIR', 'segmented_nuts'))  # default folder name\n",
    "DATASET_DIR = Path(os.getenv('DATASET_DIR', 'dataset_for_anomalib'))\n",
    "OUTPUT_DIR = Path(os.getenv('ANOMALIB_OUTPUT', 'anomalib_results'))\n",
    "\n",
    "# Training parameters\n",
    "TRAIN_RATIO = float(os.getenv('TRAIN_RATIO', 0.7))\n",
    "BATCH_SIZE = int(os.getenv('BATCH_SIZE', 16))\n",
    "IMAGE_SIZE = int(os.getenv('IMAGE_SIZE', 224))\n",
    "MAX_EPOCHS = int(os.getenv('MAX_EPOCHS', 3))\n",
    "\n",
    "print('SEGMENTED_DIR ->', SEGMENTED_DIR.resolve())\n",
    "print('DATASET_DIR ->', DATASET_DIR.resolve())\n",
    "print('OUTPUT_DIR ->', OUTPUT_DIR.resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49219c8c",
   "metadata": {},
   "source": [
    "## Step 1 — Inspect input folder\n",
    "This cell checks whether the folder contains mask files (image+mask pairs) or already-cropped images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a72b191",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "SEGMENTED_DIR.mkdir(exist_ok=True)\n",
    "images = list(SEGMENTED_DIR.glob('*.png')) + list(SEGMENTED_DIR.glob('*.jpg')) + list(SEGMENTED_DIR.glob('*.jpeg'))\n",
    "masks = [p for p in images if p.stem.endswith('_mask') or p.name.lower().endswith('_mask.png')]\n",
    "# Also look for separate mask files (any file with _mask in name)\n",
    "mask_files = list(SEGMENTED_DIR.glob('*_mask.png')) + list(SEGMENTED_DIR.glob('*_mask.jpg'))\n",
    "\n",
    "print(f'Found {len(images)} image files and {len(mask_files)} mask files in {SEGMENTED_DIR.name}')\n",
    "\n",
    "if len(mask_files) > 0:\n",
    "    print('Detected mask files. Assuming folder contains image+mask pairs.')\n",
    "    INPUT_MODE = 'image_mask_pairs'\n",
    "else:\n",
    "    print('No mask files detected. Assuming folder contains cropped nut images ready for dataset split.')\n",
    "    INPUT_MODE = 'cropped_images'\n",
    "\n",
    "INPUT_MODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cbd0c5",
   "metadata": {},
   "source": [
    "## Step 2 — Build Anomalib Dataset\n",
    "If your folder contains masks, we'll pair images and masks and produce cropped images. If it already contains cropped images, we'll create train/test splits directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610b0674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import local builders\n",
    "from anomalib_dataset_builder import AnomalibDatasetBuilder\n",
    "from segmentation_cropper import SegmentationCropper\n",
    "\n",
    "# Create dataset dir\n",
    "DATASET_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if INPUT_MODE == 'image_mask_pairs':\n",
    "    print('Using SegmentationCropper to produce cropped images from image+mask pairs...')\n",
    "    cropper = SegmentationCropper(output_base='cropped_nuts')\n",
    "    # The cropper expects Roboflow-like JSON results; we will instead pair images and masks directly here.\n",
    "    # Simple pairing: for each image file MYIMAGE.png, look for MYIMAGE_mask.png and crop region of mask.\n",
    "    cropped_base = Path('cropped_nuts')\n",
    "    cropped_base.mkdir(parents=True, exist_ok=True)\n",
    "    metadata = []\n",
    "    for img_path in sorted(SEGMENTED_DIR.glob('*.*')):\n",
    "        if img_path.name.lower().endswith(('_mask.png','_mask.jpg','_mask.jpeg')):\n",
    "            continue\n",
    "        # expected mask name\n",
    "        mask_candidates = list(SEGMENTED_DIR.glob(f\n",
    ")) + list(SEGMENTED_DIR.glob(f\n",
    "))\n",
    "        if not mask_candidates:\n",
    "            # fallback: try any mask with same name + '_mask' pattern\n",
    "            mask_candidates = list(SEGMENTED_DIR.glob(f\n",
    "))\n",
    "        if not mask_candidates:\n",
    "            # No mask found - skip\n",
    "            continue\n",
    "        mask_path = mask_candidates[0]\n",
    "        # Load images\n",
    "        import cv2, numpy as np\n",
    "        img = cv2.imread(str(img_path))\n",
    "        mask = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None or mask is None:\n",
    "            continue\n",
    "        # find contours and crop the bounding box around the mask\n",
    "        contours, _ = cv2.findContours((mask>127).astype('uint8'), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        if not contours:\n",
    "            continue\n",
    "        x,y,w,h = cv2.boundingRect(contours[0])\n",
    "        pad = 8\n",
    "        x0,y0 = max(0,x-pad), max(0,y-pad)\n",
    "        x1,y1 = min(img.shape[1], x+w+pad), min(img.shape[0], y+h+pad)\n",
    "        crop = img[y0:y1, x0:x1]\n",
    "        out_name = f\"{img_path.stem}.png\"\n",
    "        out_path = cropped_base / out_name\n",
    "        cv2.imwrite(str(out_path), crop)\n",
    "        metadata.append({'source':str(img_path), 'cropped': str(out_path)})\n",
    "    print(f'Created {len(metadata)} cropped images into {cropped_base}')\n",
    "    # Use dataset builder on cropped_nuts\n",
    "    builder = AnomalibDatasetBuilder(str(DATASET_DIR))\n",
    "    counts = builder.create_splits(str(cropped_base), train_ratio=TRAIN_RATIO)\n",
    "    print('Dataset splits:', counts)\n",
    "else:\n",
    "    print('Using provided cropped images to build dataset splits...')\n",
    "    builder = AnomalibDatasetBuilder(str(DATASET_DIR))\n",
    "    counts = builder.create_splits(str(SEGMENTED_DIR), train_ratio=TRAIN_RATIO)\n",
    "    print('Dataset splits:', counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc624b78",
   "metadata": {},
   "source": [
    "## Step 3 — Train Anomalib Model\n",
    "This will run Patchcore training using the dataset we just created. Adjust `MAX_EPOCHS` and `BATCH_SIZE` above if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4bc9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from anomalib_trainer import AnomalibTrainer\n",
    "\n",
    "trainer = AnomalibTrainer(dataset_root=str(DATASET_DIR), model_name='patchcore', backbone='wide_resnet50_2', image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, max_epochs=MAX_EPOCHS, output_dir=str(OUTPUT_DIR))\n",
    "trainer.setup_model()\n",
    "trainer.setup_trainer()\n",
    "trainer.save_config()\n",
    "dm = trainer.setup_datamodule()\n",
    "trainer.train(dm)\n",
    "results = trainer.test(dm)\n",
    "print('Training finished. Results:', results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a78f067",
   "metadata": {},
   "source": [
    "## Notes\n",
    "- This notebook assumes your segmented/cropped images are correctly centered on nuts.\n",
    "- If training fails due to missing packages, run the pip install cell above.\n",
    "- For HEIC inputs, install `pillow-heif` or convert to PNG/JPG before running."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
